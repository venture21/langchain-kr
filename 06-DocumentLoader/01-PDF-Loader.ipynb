{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66f34be",
   "metadata": {},
   "source": [
    "# PDF\n",
    "\n",
    "[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), ISO 32000으로 표준화된 파일 형식은 Adobe가 1992년에 문서를 제시하기 위해 개발했으며, 이는 응용 소프트웨어, 하드웨어 및 운영 시스템에 독립적인 방식으로 텍스트 서식 및 이미지를 포함합니다.\n",
    "\n",
    "이 가이드는 `PDF` 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) 형식으로 로드하는 방법을 다룹니다. 이 형식은 다운스트림에서 사용됩니다.\n",
    "\n",
    "LangChain은 다양한 PDF 파서와 통합됩니다. 일부는 간단하고 상대적으로 저수준이며, 다른 일부는 OCR 및 이미지 처리를 지원하거나 고급 문서 레이아웃 분석을 수행합니다. \n",
    "\n",
    "올바른 선택은 사용자의 애플리케이션에 따라 달라집니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [LangChain 도큐먼트](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3883eda",
   "metadata": {},
   "source": [
    "## AutoRAG 팀에서의 PDF 실험\n",
    "\n",
    "AutoRAG 에서 진행한 실험을 토대로 작성한 순위표\n",
    "\n",
    "아래 표기된 숫자는 등수를 나타냅니다. (The lower, the better)\n",
    "\n",
    "| | PDFMiner | PDFPlumber | PyPDFium2 | PyMuPDF | PyPDF2 |\n",
    "|----------|:---------:|:----------:|:---------:|:-------:|:-----:|\n",
    "| Medical  | 1         | 2          | 3         | 4       | 5     |\n",
    "| Law      | 3         | 1          | 1         | 3       | 5     |\n",
    "| Finance  | 1         | 2          | 2         | 4       | 5     |\n",
    "| Public   | 1         | 1          | 1         | 4       | 5     |\n",
    "| Sum      | 5         | 5          | 7         | 15      | 20    |\n",
    "\n",
    "출처: [AutoRAG Medium 블로그](https://velog.io/@autorag/PDF-%ED%95%9C%EA%B8%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%B6%94%EC%B6%9C-%EC%8B%A4%ED%97%98#%EC%B4%9D%ED%8F%89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1907c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f023d22",
   "metadata": {},
   "source": [
    "## 실습에 활용한 문서\n",
    "\n",
    "소프트웨어정책연구소(SPRi) - 2023년 12월호\n",
    "\n",
    "- 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "- 링크: https://spri.kr/posts/view/23669\n",
    "- 파일명: `SPRI_AI_Brief_2023년12월호_F.pdf`\n",
    "\n",
    "**참고**: 위의 파일은 `data` 폴더 내에 다운로드 받으세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1978423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c404e7d",
   "metadata": {},
   "source": [
    "## PyPDF\n",
    "\n",
    "여기에서는 `pypdf`를 사용하여 PDF를 문서 배열로 로드하며, 각 문서는 `page` 번호와 함께 페이지 내용 및 메타데이터를 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9673857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5180451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page14.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa20caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Z. Shen et al. \n",
      "6 Conclusion \n",
      "LayoutParser provides a comprehensive toolkit for deep learning-based document \n",
      "image analysis. The off-the-shelf library is easy to install, and can be used to \n",
      "build flexible and accurate pipelines for processing documen ts with complicated \n",
      "structures. It also supports high-level customization and enables easy labeling and \n",
      "training of DL models on unique documen t image datasets. The LayoutParser \n",
      "community platform facilitates sharing DL models and DIA pipelines, inviting \n",
      "discussion and promoting code reproducibility and reusability. The LayoutParser \n",
      "team is committed to keeping the library updated continuously and bringing \n",
      "the most recent advances in DL-based DIA, such as multi-modal documen t \n",
      "modeling [37, 36, 9] (an upcoming priority), to a diverse audience of end-users. \n",
      "Acknowled gements We thank the anonymous reviewers for their comments \n",
      "and suggestions. This project is supported in part by NSF Grant OIA-2033558 \n",
      "and funding from the Harvard Data Science Initiative and Harvard Catalyst. \n",
      "Zejiang Shen thanks Doug Downey for suggestions. \n",
      "References \n",
      "[I] Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, \n",
      "G.S., Davis, A., Dean, J., Devin, M., Ghemawa t, S., Goodfellow, I., Harp, A., \n",
      "Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenber g, \n",
      "J., Mane, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., \n",
      "Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., \n",
      "Viegas, F., Vinyals, 0., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., Zheng, \n",
      "X.: TensorFlow: Large-scale machine learning on heterogeneous systems (2015), \n",
      "https : //www . tensorflow . org/, software available from tensorflow.org \n",
      "[2] Alberti, M., Pondenkanda th, V., Wiirsch, M., Ingold, R., Liwicki, M.: Deepdiva: a \n",
      "highly-functional python framework for reproducible experiments. In: 2018 16th \n",
      "International Conference on Frontiers in Handwriting Recognition (ICFHR) . pp. \n",
      "423-428. IEEE (2018) \n",
      "[3] Antonacopoulos, A., Bridson, D., Papadopoulos, C., Pletschacher, S.: A realistic \n",
      "dataset for performance evaluation of document layout analysis. In: 2009 10th \n",
      "International Conference on Documen t Analysis and Recognition. pp. 296—300. \n",
      "IEEE (2009) \n",
      "[4] Baek, Y., Lee, B., Han, D., Yun, S., Lee, H.: Character region awareness for text \n",
      "detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and \n",
      "Pattern Recognition. pp. 9365—9374 (2019) \n",
      "[5] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: ImageNet: A Large-Scale \n",
      "Hierarchical Image Database. In: CVPR09 (2009) \n",
      "[6] Deng, Y., Kanervisto, A., Ling, J., Rush, A.M.: Image-to-markup generation with \n",
      "coarse-to-fine attention. In: International Conference on Machine Learning. pp. \n",
      "980—989. PMLR (2017) \n",
      "[까 Ganin, Y., Lempitsky, V.: Unsupervised domain adaptation by backpropagation. \n",
      "In: International conference on machine learning. pp. 1180—1189. PMLR (2015)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "# print(docs[10].page_content[:300])\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453f2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PyPDF\n",
      "creationdate : 2025-08-22T12:40:57+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:48:05+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "source       : ./data/2103_page14.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 출력\n",
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96845496",
   "metadata": {},
   "source": [
    "### PyPDF(OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e3c86",
   "metadata": {},
   "source": [
    "일부 PDF에는 스캔된 문서나 그림 내에 텍스트 이미지가 포함되어 있습니다. `rapidocr-onnxruntime` 패키지를 사용하여 이미지에서 텍스트를 추출할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267c13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"./data/2103_page4.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5334000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Z. Shen et al. \n",
      ".z-\n",
      "Efficient Data Annotation I f \n",
      "Customized Model Training I ~ I Layout Detection Models I ~ I DIA Pipeline Sharing ’ \n",
      "'—` \n",
      "OCRModule 〕一Layout Data Structure ’ ’ \n",
      "一 Fig.1: The overall architecture of LayoutParser. For an input document image, \n",
      "the core LayoutParser library provides a set of off-the-shelf tools for layout \n",
      "detection, OCR, visualization, and storage, backed by a carefully designed layout \n",
      "data structure. LayoutParser also supports high level customization via efficient \n",
      "layout annotation and model training functions. These improve model accuracy \n",
      "on the target samples. The community platform enables the easy sharing of DIA \n",
      "models and whole digitization pipelines to promote reusability and reproducibility. \n",
      "A collection of detailed documen tation, tutorials and exemplar projects make \n",
      "LayoutParser easy to learn and use. \n",
      "AllenNLP [8] and transformers [34] have provided the community with complete \n",
      "DL-based support for developing and deploying models for general computer \n",
      "vision and natural language processing problems. LayoutParser, on the other \n",
      "hand, specializes specifically in DIA tasks. LayoutParser is also equipped with a \n",
      "community platform inspired by established model hubs such as Torch Hub [23] \n",
      "and TensorFlow Hub [1] . It enables the sharing of pretrained models as well as \n",
      "full document processing pipelines that are unique to DIA tasks. \n",
      "There have been a variety of documen t data collections to facilitate the \n",
      "development of DL models. Some examples include PRlmA [3] (magazine layouts) , \n",
      "PubLayNet [38](academ ic paper layouts), Table Bank [18](tables in academic \n",
      "papers) , Newspaper Navigator Dataset [16, 17](newspaper figure layouts) and \n",
      "HJDataset [31] (historical Japanese documen t layouts) . A spectrum of models \n",
      "trained on these datasets are currently available in the LayoutParser model zoo \n",
      "to support different use cases. \n",
      "3 The Core LayoutParser Library \n",
      "At the core of LayoutParser is an off-the-shelf toolkit that streamlines DL­\n",
      "based documen t image analysis. Five components support a simple interface \n",
      "with comprehensive functionalities: 1) The layout detection models enable using \n",
      "pre-trained or self-trained DL models for layout detection with just four lines \n",
      "of code. 2) The detected layout information is stored in carefully engineered\n"
     ]
    }
   ],
   "source": [
    "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
    "# loader = PyPDFLoader(\"https://arxiv.org/pdf/2103.15348.pdf\", extract_images=True)\n",
    "loader = PyPDFLoader(FILE_PATH, extract_images=True)\n",
    "# PDF 페이지 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 페이지 내용 접근\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fe6caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PyPDF\n",
      "creationdate : 2025-08-22T12:39:06+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:47:22+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "source       : ./data/2103_page4.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a191d5c",
   "metadata": {},
   "source": [
    "## PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88bca1",
   "metadata": {},
   "source": [
    "**PyMuPDF** 는 속도 최적화가 되어 있으며, PDF 및 해당 페이지에 대한 자세한 메타데이터를 포함하고 있습니다. 페이지 당 하나의 문서를 반환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac56d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e7a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \n",
      "Z. Shen et al. \n",
      ".z-\n",
      "Efficient Data Annotation I \n",
      "f \n",
      "Customized Model Training I ~ \n",
      "I Layout Detection Models I ~ \n",
      "I \n",
      "DIA Pipeline Sharing \n",
      "’ \n",
      "'—` \n",
      "OCRModule \n",
      "〕一\n",
      "Layout Data Structure \n",
      "’ \n",
      "’ \n",
      "一\n",
      "Fig.1: The overall architecture of Layout Parser. For an input document image, \n",
      "t he core Layout Parser library provides a set of off-the-shelf tools for layout \n",
      "detection, OCR, visualization, and storage, backed by a carefully designed layout \n",
      "data struct ure. Layout Parser also supports high level customization via efficient \n",
      "layout annotation and model training functions. These improve model accuracy \n",
      "on the target samples. The community platform enables t he easy sharing of DIA \n",
      "models and whole digitization pipelines to promote reusability and reproducibility. \n",
      "A collection of det ailed documentation, t utorials and exemplar projects make \n",
      "Layout Parser easy to learn and use. \n",
      "AllenNLP [8] and transformers [34] have provided the community with complete \n",
      "DL-based support for developing and deploying models for general computer \n",
      "vision and nat ural language processing problems. Layout Parser, on t he ot her \n",
      "hand, specializes specifically in DIA tasks. Layout Parser is also equipped with a \n",
      "community platform inspired by established model hubs such as Torch Hub [23] \n",
      "and TensorFlow Hub [1] . It enables t he sharing of pretrained models as well as \n",
      "full document processing pipelines that are unique to DIA tasks. \n",
      "There have been a variety of document data collections to facilitate t he \n",
      "development of DL models. Some examples include PRlmA [3] (magazine layouts) , \n",
      "PubLayNet [38](academic paper layouts), Table Bank [18](tables in academic \n",
      "papers) , Newspaper Navigator Dataset [16, 17](newspaper figure layouts) and \n",
      "HJDat aset [31] (historical Japanese document layouts) . A spectrum of models \n",
      "trained on t hese datasets are currently available in t he Layout Parser model zoo \n",
      "to support different use cases. \n",
      "3 \n",
      "The Core Layout Parser Library \n",
      "At t he core of Layout Parser is an off-the-shelf toolkit that streamlines DL-\n",
      "based document image analysis. Five components support a simple interface \n",
      "with comprehensive functionalities: 1) The layout detection models enable using \n",
      "pre-trained or self-trained DL models for layout detection with j ust four lines \n",
      "of code. 2) The detected layout information is stored in carefully engineered\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbca8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'source', 'file_path', 'total_pages', 'format', 'title', 'author', 'subject', 'keywords', 'moddate', 'trapped', 'modDate', 'creationDate', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : \n",
      "creationdate : 2025-08-22T12:39:06+09:00\n",
      "source       : ./data/2103_page4.pdf\n",
      "file_path    : ./data/2103_page4.pdf\n",
      "total_pages  : 1\n",
      "format       : PDF 1.7\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "author       : Heejin Park\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2025-08-22T12:47:22+09:00\n",
      "trapped      : \n",
      "modDate      : D:20250822124722+09'00'\n",
      "creationDate : D:20250822123906+09'00'\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89745c9",
   "metadata": {},
   "source": [
    "## Unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199f11",
   "metadata": {},
   "source": [
    "[Unstructured](https://unstructured-io.github.io/unstructured/)는 Markdown이나 PDF와 같은 비구조화된 또는 반구조화된 파일 형식을 다루기 위한 공통 인터페이스를 지원합니다. \n",
    "\n",
    "LangChain의 [UnstructuredPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html)는 Unstructured와 통합되어 PDF 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html) 객체로 파싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU unstructured\n",
    "FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40cb362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년 12월호\n",
      "\n",
      "2023년 12월호\n",
      "\n",
      "Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "1. 정책/법제\n",
      "\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ························· 1\n",
      "\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의 ··························· 2\n",
      "\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언 ··························· 3\n",
      "\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# UnstructuredPDFLoader 인스턴스 생성\n",
    "loader = UnstructuredPDFLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926b929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source']\n",
      "\n",
      "[examples]\n",
      "source : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115d62b",
   "metadata": {},
   "source": [
    "내부적으로 비정형에서는 텍스트 청크마다 서로 다른 \"**요소**\"를 만듭니다. 기본적으로 이들은 결합되어 있지만 `mode=\"elements\"`를 지정하여 쉽게 분리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f97007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년 12월호\n"
     ]
    }
   ],
   "source": [
    "# UnstructuredPDFLoader 인스턴스 생성(mode=\"elements\")\n",
    "loader = UnstructuredPDFLoader(FILE_PATH, mode=\"elements\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab703e",
   "metadata": {},
   "source": [
    "이 특정 문서에 대한 전체 요소 유형 집합을 참조하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fd7976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(doc.metadata[\"category\"] for doc in docs)  # 데이터 카테고리 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5097872",
   "metadata": {},
   "source": [
    "## PyPDFium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c84bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief | \n",
      "2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어(Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\pypdfium2\\_helpers\\textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDFium2 로더 인스턴스 생성\n",
    "loader = PyPDFium2Loader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b2a6a",
   "metadata": {},
   "source": [
    "## PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5feac159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년  12월호\n",
      "\f2023년  12월호\n",
      "\n",
      "Ⅰ.  인공지능  산업  동향  브리프\n",
      "\n",
      "  1.  정책/법제 \n",
      "\n",
      "      ▹  미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표    ························· 1\n",
      "\n",
      "      ▹  G7,  히로시마  AI  프로세스를  통해  AI  기업  대상  국제  행동강령에  합의 ··························· 2\n",
      "\n",
      "      ▹  영국  AI  안전성  정상회의에  참가한  28개국,  AI  위험에  공동  \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "# PDFMiner 로더 인스턴스 생성\n",
    "loader = PDFMinerLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a85f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d918ef7",
   "metadata": {},
   "source": [
    "**PDFMiner**를 사용하여 HTML 텍스트 생성\n",
    "\n",
    "이 방법은 출력된 HTML 콘텐츠를 `BeautifulSoup`을 통해 파싱함으로써 글꼴 크기, 페이지 번호, PDF 헤더/푸터 등에 대한 보다 구조화되고 풍부한 정보를 얻을 수 있게 하여 텍스트를 의미론적으로 섹션으로 분할하는 데 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d299c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html\">\n",
      "</head><body>\n",
      "<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span>\n",
      "<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\n",
      "<div style=\"position:absolute; border\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "\n",
    "# PDFMinerPDFasHTMLLoader 인스턴스 생성\n",
    "loader = PDFMinerPDFasHTMLLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aacfd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source']\n",
      "\n",
      "[examples]\n",
      "source : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df728c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(docs[0].page_content, \"html.parser\")  # HTML 파서 초기화\n",
    "content = soup.find_all(\"div\")  # 모든 div 태그 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d75111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cur_fs = None\n",
    "cur_text = \"\"\n",
    "snippets = []  # 동일한 글꼴 크기의 모든 스니펫 수집\n",
    "for c in content:\n",
    "    sp = c.find(\"span\")\n",
    "    if not sp:\n",
    "        continue\n",
    "    st = sp.get(\"style\")\n",
    "    if not st:\n",
    "        continue\n",
    "    fs = re.findall(\"font-size:(\\d+)px\", st)\n",
    "    if not fs:\n",
    "        continue\n",
    "    fs = int(fs[0])\n",
    "    if not cur_fs:\n",
    "        cur_fs = fs\n",
    "    if fs == cur_fs:\n",
    "        cur_text += c.text\n",
    "    else:\n",
    "        snippets.append((cur_text, cur_fs))\n",
    "        cur_fs = fs\n",
    "        cur_text = c.text\n",
    "snippets.append((cur_text, cur_fs))\n",
    "# 중복 스니펫 제거 전략 추가 가능성 (PDF의 헤더/푸터가 여러 페이지에 걸쳐 나타나므로 중복 발견 시 중복 정보로 간주 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8061d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='KEY Contents\n",
      "n 미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령’에 서명하고 \n",
      "광범위한  행정  조치를  명시\n",
      "n 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 \n",
      "보호  △노동자  지원  △혁신과  경쟁  촉진  △국제협력을  골자로  함\n",
      "' metadata={'heading': '미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표 \\n', 'content_font': 12, 'heading_font': 15, 'source': './data/SPRI_AI_Brief_2023년12월호_F.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "cur_idx = -1\n",
    "semantic_snippets = []\n",
    "# 제목 가정: 높은 글꼴 크기\n",
    "for s in snippets:\n",
    "    # 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\n",
    "    if (\n",
    "        not semantic_snippets\n",
    "        or s[1] > semantic_snippets[cur_idx].metadata[\"heading_font\"]\n",
    "    ):\n",
    "        metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "        metadata.update(docs[0].metadata)\n",
    "        semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "        cur_idx += 1\n",
    "        continue\n",
    "\n",
    "    # 동일 섹션 내용 판별: 현재 스니펫 글꼴 <= 이전 내용 글꼴\n",
    "    if (\n",
    "        not semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        or s[1] <= semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "    ):\n",
    "        semantic_snippets[cur_idx].page_content += s[0]\n",
    "        semantic_snippets[cur_idx].metadata[\"content_font\"] = max(\n",
    "            s[1], semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # 새 섹션 생성 조건: 현재 스니펫 글꼴 > 이전 내용 글꼴, 이전 제목 글꼴 미만\n",
    "    metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "    metadata.update(docs[0].metadata)\n",
    "    semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "    cur_idx += 1\n",
    "\n",
    "print(semantic_snippets[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0740f50",
   "metadata": {},
   "source": [
    "## PyPDF 디렉토리\n",
    "\n",
    "디렉토리에서 PDF를 로드하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93bbbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 디렉토리 경로\n",
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 개수 출력\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "231ffd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutParser: A Unified Toolkit for Deep \n",
      "Learning Based Documen t Image Analysis \n",
      "IZOZ \n",
      "unr \n",
      "It Zejiang Shen1 詞),Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain \n",
      "Lee4, Jacob Carlson3, and Weining Li5 \n",
      "1 Allen Institute for AI \n",
      "shannons©allena i.org \n",
      "2 Brown University \n",
      "ruochen_zhan g©brown.\n"
     ]
    }
   ],
   "source": [
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c68b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 출력\n",
    "print(docs[50].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb92d77",
   "metadata": {},
   "source": [
    "## PDFPlumber\n",
    "\n",
    "PyMuPDF와 마찬가지로, 출력 문서는 PDF와 그 페이지에 대한 자세한 메타데이터를 포함하며, 페이지 당 하나의 문서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e97bd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "KEY Contents\n",
      "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태,\n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의\n",
      "구성과 계보도 추적 가능\n",
      "£데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어(Cohere)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# PDF 문서 로더 인스턴스 생성\n",
    "loader = PDFPlumberLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 첫 번째 문서 데이터 접근\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0c637a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ pdfminer.six==20220319 설치 완료\n",
      "✓ unstructured[pdf]==0.10.30 설치 완료\n",
      "\n",
      "패키지 설치 완료. 커널을 재시작하고 다시 시도해주세요.\n",
      "✓ unstructured[pdf]==0.10.30 설치 완료\n",
      "\n",
      "패키지 설치 완료. 커널을 재시작하고 다시 시도해주세요.\n"
     ]
    }
   ],
   "source": [
    "# pdfminer 호환성 문제 해결을 위한 패키지 설치\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_compatible_packages():\n",
    "    \"\"\"호환되는 버전의 패키지들 설치\"\"\"\n",
    "    packages = [\n",
    "        \"pdfminer.six==20220319\",  # 호환되는 구 버전\n",
    "        \"unstructured[pdf]==0.10.30\",  # 호환되는 unstructured 버전\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✓ {package} 설치 완료\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ {package} 설치 실패: {e}\")\n",
    "\n",
    "\n",
    "# 호환 패키지 설치 실행\n",
    "install_compatible_packages()\n",
    "print(\"\\n패키지 설치 완료. 커널을 재시작하고 다시 시도해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hTuzgesB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
