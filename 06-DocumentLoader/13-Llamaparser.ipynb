{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8382978f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LlamaParser\n",
    " \n",
    "LlamaParseëŠ” LlamaIndexì—ì„œ ê°œë°œí•œ ë¬¸ì„œ íŒŒì‹± ì„œë¹„ìŠ¤ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- PDF, Word, PowerPoint, Excel ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ ì§€ì›\n",
    "- ìì—°ì–´ ì§€ì‹œë¥¼ í†µí•œ ë§ì¶¤í˜• ì¶œë ¥ í˜•ì‹ ì œê³µ\n",
    "- ë³µì¡í•œ í‘œì™€ ì´ë¯¸ì§€ ì¶”ì¶œ ê¸°ëŠ¥\n",
    "- JSON ëª¨ë“œ ì§€ì›\n",
    "- ì™¸êµ­ì–´ ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ec026",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca7f57",
   "metadata": {},
   "source": [
    "LlamaParseëŠ” ë…ë¦½í˜• APIë¡œ ì œê³µë˜ë©°, LlamaCloud í”Œë«í¼ì˜ ì¼ë¶€ë¡œë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ì„œë¹„ìŠ¤ëŠ” ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  ì •ì œí•˜ì—¬ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) ë“± LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ìëŠ” ë¬´ë£Œë¡œ í•œë‹¬ì— 10,000í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ìœ ë£Œ í”Œëœì„ í†µí•´ ì¶”ê°€ ìš©ëŸ‰ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LlamaParseëŠ” í˜„ì¬ ê³µê°œ ë² íƒ€ ë²„ì „ìœ¼ë¡œ ì œê³µë˜ê³  ìˆìœ¼ë©°, ì§€ì†ì ìœ¼ë¡œ ê¸°ëŠ¥ì´ í™•ì¥ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ë§í¬: https://cloud.llamaindex.ai\n",
    "\n",
    "**API í‚¤ ì„¤ì •**\n",
    "- API í‚¤ë¥¼ ë°œê¸‰ í›„ `.env` íŒŒì¼ì— `LLAMA_CLOUD_API_KEY` ì— ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de92eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì¹˜\n",
    "# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850910e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# jupyter í™˜ê²½ì—ì„œ asyncioë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •\n",
    "# ì´ëŠ” Jupyter Notebookì—ì„œ ë¹„ë™ê¸° ì‘ì—…ì„ ì§€ì›í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3b85",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ íŒŒì„œ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a94cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0c29b0be-a687-42f1-b7bf-2805f04a458c\n",
      "."
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# íŒŒì„œ ì„¤ì •\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"ê³¼ \"text\" ì‚¬ìš© ê°€ëŠ¥\n",
    "    num_workers=8,  # worker ìˆ˜ (ê¸°ë³¸ê°’: 4)\n",
    "    verbose=True,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReaderë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ íŒŒì‹±\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParseë¡œ íŒŒì‹±í•˜ê³ ìí•˜ëŠ” íŒŒì¼ ëª©ë¡ì„ input_filesì— ì§€ì •í•©ë‹ˆë‹¤.\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4aabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í˜ì´ì§€ ìˆ˜ í™•ì¸\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a08fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='128451be-2864-49f0-a173-4a28fc5ac9bd', embedding=None, metadata={'file_path': 'data\\\\SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf', 'file_name': 'SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-08-21', 'last_modified_date': '2025-08-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='# ì¸ê³µì§€ëŠ¥ ì‚°ì—…ì˜ ìµœì‹  ë™í–¥\\n\\n# 2023ë…„ 12ì›”í˜¸\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d4e1b",
   "metadata": {},
   "source": [
    "LlamaIndex -> LangChain Document ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10be578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë­ì²´ì¸ ë„íë¨¼íŠ¸ë¡œ ë³€í™˜\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db68c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "6  Z. Shen et al.\n",
      "\n",
      "Fig. 2: The relationship between the three types of layout data structures. Coordinate supports three kinds of variation; TextBlock consists of the coordinate information and extra features like block text, types, and reading orders; a Layout object is a list of all possible layout elements, including other Layout objects. They all support the same set of transformation and operation APIs for maximum flexibility.\n",
      "\n",
      "Shown in Table 1, LayoutParser currently hosts 9 pre-trained models trained on 5 different datasets. Description of the training dataset is provided alongside with the trained models such that users can quickly identify the most suitable models for their tasks. Additionally, when such a model is not readily available, LayoutParser also supports training customized layout models and community sharing of the models (detailed in Section 3.5).\n",
      "\n",
      "# 3.2  Layout Data Structures\n",
      "\n",
      "A critical feature of LayoutParser is the implementation of a series of data structures and operations that can be used to efficiently process and manipulate the layout elements. In document image analysis pipelines, various post-processing on the layout analysis model outputs is usually required to obtain the final outputs. Traditionally, this requires exporting DL model outputs and then loading the results into other pipelines. All model outputs from LayoutParser will be stored in carefully engineered data types optimized for further processing, which makes it possible to build an end-to-end document digitization pipeline within LayoutParser. There are three key components in the data structure, namely the Coordinate system, the TextBlock, and the Layout. They provide different levels of abstraction for the layout data, and a set of APIs are supported for transformations or operations on these classes.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ec141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data\\\\2103.15348v2.pdf',\n",
       " 'file_name': '2103.15348v2.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 4686220,\n",
       " 'creation_date': '2025-08-22',\n",
       " 'last_modified_date': '2025-08-22'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata ì¶œë ¥\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845a3bc",
   "metadata": {},
   "source": [
    "## MultiModal Model ë¡œ íŒŒì‹±\n",
    "\n",
    "**ì£¼ìš” íŒŒë¼ë¯¸í„°**\n",
    "\n",
    "- `use_vendor_multimodal_model`: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. `True`ë¡œ ì„¤ì •í•˜ë©´ ì™¸ë¶€ ë²¤ë”ì˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `vendor_multimodal_model_name`: ì‚¬ìš©í•  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” \"openai-gpt4o\"ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- `vendor_multimodal_api_key`: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ API í‚¤ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "- `result_type`: íŒŒì‹± ê²°ê³¼ì˜ í˜•ì‹ì„ ì§€ì •í•©ë‹ˆë‹¤. \"markdown\"ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ê²°ê³¼ê°€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "- `language`: íŒŒì‹±í•  ë¬¸ì„œì˜ ì–¸ì–´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. \"ko\"ë¡œ ì„¤ì •ë˜ì–´ í•œêµ­ì–´ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
    "\n",
    "- `skip_diagonal_text`: ëŒ€ê°ì„  í…ìŠ¤íŠ¸ë¥¼ ê±´ë„ˆë›¸ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `page_separator`: í˜ì´ì§€ êµ¬ë¶„ìë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI = False\n",
    "if GEMINI:\n",
    "    multimodal_model_name = \"gemini-2.5-pro\"\n",
    "    multimodal_api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "else:\n",
    "    multimodal_model_name = \"openai-gpt4o\"\n",
    "    multimodal_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "    # LlamaParse ì„¤ì •\n",
    "\n",
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=multimodal_model_name,\n",
    "    vendor_multimodal_api_key=multimodal_api_key,\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c986f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b50de87a-8447-4ad7-bb79-3bd4e513838f\n"
     ]
    }
   ],
   "source": [
    "# parsing ëœ ê²°ê³¼\n",
    "# file_path = \"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\"\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55bb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain ë„íë¨¼íŠ¸ë¡œ ë³€í™˜\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb571cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/2103.15348v2.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)\n",
    "\n",
    "# langchain ë„íë¨¼íŠ¸ë¡œ ë³€í™˜\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "# os.path.splitext()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½ë¡œì™€ í™•ì¥ìë¥¼ ë¶„ë¦¬í•˜ê³ , ìƒˆë¡œìš´ í™•ì¥ìë¥¼ ë¶™ì…ë‹ˆë‹¤.\n",
    "# file_rootëŠ” 'data/2103.15348v2'ê°€ ë©ë‹ˆë‹¤.\n",
    "file_root, _ = os.path.splitext(file_path)\n",
    "output_file_path = file_root + \".md\"\n",
    "\n",
    "# 1. ëª¨ë“  í˜ì´ì§€ì˜ page_contentë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "#    ê° í˜ì´ì§€ ì‚¬ì´ë¥¼ ë‘ ì¤„ ë„ì–´ì“°ê¸°(\\n\\n)ë¡œ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 2. ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "#    'w' ëª¨ë“œëŠ” íŒŒì¼ì„ ì“°ê¸° ëª¨ë“œë¡œ ì—´ë©°, encoding='utf-8'ì€ í•œê¸€ ê¹¨ì§ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efd3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. ì •ì±…/ì •ì±…\n",
      "\n",
      "# ë¯¸êµ­, ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œê³¼ ì‚¬ìš©ì— ê´€í•œ í–‰ì •ëª…ë ¹ ë°œí‘œ\n",
      "\n",
      "**KEY Contents**\n",
      "\n",
      "- ë¯¸êµ­ ë°”ì´ë“  ëŒ€í†µë ¹ì´ 'ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œê³¼ ì‚¬ìš©ì— ê´€í•œ í–‰ì •ëª…ë ¹'ì— ì„œëª…í•˜ê³  ê´‘ë²”ìœ„í•œ í–‰ì • ì¡°ì¹˜ë¥¼ ëª…ì‹œ\n",
      "- í–‰ì •ëª…ë ¹ì€ AIì˜ ì•ˆì „ê³¼ ë³´ì•ˆ ê¸°ì¤€ ë§ˆë ¨, ê°œì¸ì •ë³´ë³´í˜¸, ì†Œí–‰ì„±í™”ì™€ ì‹œë¯¼ê¶Œ í–¥ìƒ, ì†Œë¹„ì ë³´í˜¸, ë…¸ë™ì ì§€ì›, ìŠµì‹ë‚´ ê²½ìŸ ì´‰ì§„, ìŠ¤í¬ì¬í˜‘ë ¥ì„ ê³¨ìë¡œ í•¨\n",
      "\n",
      "## ë°”ì´ë“  ëŒ€í†µë ¹, AI í–‰ì •ëª…ë ¹ í†µí•´ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œê³¼ í™œìš© ì¶”ì§„\n",
      "\n",
      "- ë¯¸êµ­ ë°”ì´ë“  ëŒ€í†µë ¹ì´ 2023ë…„ 10ì›” 30ì¼ ì—°ë°©ì •ë¶€ ì°¨ì›ì—ì„œ ì•ˆì „í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œê³¼ ì‚¬ìš©ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ í–‰ì •ëª…ë ¹ì„ ë°œí‘œ\n",
      "- í–‰ì •ëª…ë ¹ì€ AIì˜ ì•ˆì „ê³¼ ë³´ì•ˆ ê¸°ì¤€ ë§ˆë ¨, ê°œì¸ì •ë³´ë³´í˜¸, ì†Œí–‰ì„±í™”ì™€ ì‹œë¯¼ê¶Œ í–¥ìƒ, ì†Œë¹„ì ë³´í˜¸, ë…¸ë™ì ì§€ì›, ìŠµì‹ë‚´ ê²½ìŸ ì´‰ì§„, ìŠ¤í¬ì¬í˜‘ë ¥ì— ê´€í•œ ë‚´ìš©ì„ í¬í•¨\n",
      "- (AI ì•ˆì „ê³¼ ë³´ì•ˆ ê¸°ì¤€) ê°•í™”ëœ AI ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ê¸°ì—…ì—ê²Œ ì•ˆì „ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ì‹œìŠ¤í…œì— ê´€í•œ ì£¼ìš” ì •ë³´ë¥¼ ë¯¸êµ­ ì •ë¶€ì™€ ê³µìœ í•  ê²ƒì„ ìš”êµ¬í•˜ê³ , AI ì‹œìŠ¤í…œì˜ ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„± í™•ì¸ì„ ìœ„í•œ í‘œì¤€ ë° AI ìƒì„± ì½˜í…ì¸  í‘œì‹œë¥¼ ìœ„í•œ í‘œì¤€ê³¼ ëª¨ë°”ì¼ AI í™œìš©ì„ ì¶”ì§„\n",
      "- 10<sup>26</sup> í”Œë¡­ìŠ¤(FLOPS, Floating Point Operation Per Second)ë¥¼ ì´ˆê³¼í•˜ëŠ” ì»´í“¨í„° ì„±ëŠ¥ ë˜ëŠ” ìƒìš©í™”ì  ì„œì—´ ë°ì´í„°ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” 10<sup>3</sup>í”Œë¡­ìŠ¤ë¥¼ ì´ˆê³¼í•˜ëŠ” ì»´í“¨í„° ì„±ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ìŠ¤íƒ ë”© ë°ì´í„°ì„¼í„°ì—ì„œ 1,000ê¸°ê°€ ì´ìƒì˜ ë„¤íŠ¸ì›Œí¬ë¡œ ì—°ê²°ë˜ë©° AI í›ˆë ¨ì—ì„œ ì´ë¡œí•œ ìµœëŒ€ 10<sup>20</sup> í”Œë¡­ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì»´í“¨í„° ìš©ëŸ‰ì„ ê°–ì¶˜ í´ëŸ¬ìŠ¤í„°ê°€ ì •ë³´ê³µìœ  ìš”êµ¬ëŒ€ìƒ\n",
      "- (í–‰ë™ì„±ê³¼ ì‹œë¯¼ê¶Œ í–¥ìƒ) ë²•ë¥ , ì£¼íƒ, ë³´ê±´ ë¶„ì•¼ì—ì„œ AIì˜ ë¬´ì±…ì„í•œ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì°¨ë³„ê³¼ í¸ê²¬ ë° ê¸°íƒ€ ë¬¸ì œë¥¼ ë°©ì§€í•˜ëŠ” ì¡°ì¹˜ë¥¼ í™•ëŒ€\n",
      "- í˜•ì‚¬ì‚¬ë²• ì‹œìŠ¤í…œì—ì„œ AI ì‚¬ìš© ëª¨ë²”ì‚¬ë¡€ë¥¼ ê°œë°œí•˜ê³ , ì£¼íƒ ì„ëŒ€ ì‹œ AI ì•Œê³ ë¦¬ì¦˜ ì°¨ë³„ì„ ë§‰ê¸° ìœ„í•œ ëª…í™•í•œ ì§€ì¹¨ì„ ì œê³µí•˜ë©°, ë³´ê±´ë³µì§€ ë¶€ë¬¸ì—ì„œ ì±…ì„ ìˆëŠ” AI ë°°í¬ì™€ ì‚¬ìš©ì„ ìœ„í•œ ì „ëµì„ ë§ˆë ¨\n",
      "- (ì†Œë¹„ì ë³´í˜¸ì™€ ê·¼ë¡œì ì§€ì›) ì˜ë£Œ ë¶„ì•¼ì—ì„œ ì±…ì„ ìˆëŠ” AI ì‚¬ìš©ì„ ì´‰ì§„í•˜ê³  ë§ì¶¤í˜• ê°œì¸êµìŠµ ë“± í•™êµ ë‚´ AI êµìœ¡ ë„êµ¬ ê´€ë ¨ ìì›ì„ ê°œë°œí•˜ë©°, AIë¡œ ì¸í•œ ê·¼ë¡œì í”¼í•´ë¥¼ ì™„í™”í•˜ê³  ì´ì ì„ ê·¹ëŒ€í™”í•˜ëŠ” ì›ì¹™ê³¼ ëª¨ë²”ì‚¬ë¡€ë¥¼ ë§ˆë ¨\n",
      "- (í˜ì‹ ê³¼ ê²½ìŸ ì´‰ì§„) êµ­ê°€AIì—°êµ¬ìì›(National Artificial Intelligence Research Resource, NAIRR)ì„ í†µí•´ ë¯¸êµ­ ì „ì—­ì˜ AI ì—°êµ¬ë¥¼ ì´‰ì§„í•˜ê³ , ì¤‘ì†Œê¸°ì—…ê³¼ ê°œë°œìì˜ ê¸°ìˆ ê³¼ ì¸í”„ë¼ë¥¼ ì§€ì›\n",
      "  - êµ­ê°€ ì°¨ì›ì—ì„œ AI ì—°êµ¬ ì¸í”„ë¼ë¥¼ í™•ì¶©í•´ ë” ë§ì€ AI ì—°êµ¬ìì—ê²Œ ì¸í”„ë¼ë¥¼ ì§€ì›í•˜ëŠ” í”„ë¡œê·¸ë¨\n",
      "  - ë¹„ì ê¸°ì¤€ì„ ë””ì§€í„¸ ì í•©ì„±ì— ê°„ì†Œí™”ë¡œ AI ê´€ë ¨ ì£¼ìš” ë¶„ì•¼ì˜ ì „ë¬¸ ìê²©ì„ ê°–ì¶˜ ì™¸êµ­ì¸ë“¤ì´ ë¯¸êµ­ì—ì„œ ê³µë¶€í•˜ê³  ì·¨ì—…í•  ìˆ˜ ìˆë„ë¡ ì§€ì›\n",
      "\n",
      "ì¶œì²˜: The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (E.O. 14110), 2023.10.30.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc038703",
   "metadata": {},
   "source": [
    "ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©ì ì •ì˜ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ì„ ì§€ì •í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing instruction ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse ì„¤ì •\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing ëœ ê²°ê³¼\n",
    "parsed_docs = parser.load_data(file_path=file_path)\n",
    "\n",
    "# langchain ë„íë¨¼íŠ¸ë¡œ ë³€í™˜\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œëœ í…Œì´ë¸” í™•ì¸\n",
    "print(docs[-2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec963cd",
   "metadata": {},
   "source": [
    "### LLAMA_PARSERë¥¼ í•¨ìˆ˜ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c33002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ './data/í´ë¼ìš°ë“œë„¤ì´í‹°ë¸Œ1-2.pdf' íŒŒì¼ íŒŒì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "Started parsing the file under job_id 555fa74a-64fb-45be-b0d6-052addd2f4c3\n",
      "âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: ./data/í´ë¼ìš°ë“œë„¤ì´í‹°ë¸Œ1-2.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\")\n",
    "\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ê·¸ ë‚´ìš©ì„ Markdown íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): ì²˜ë¦¬í•  PDF íŒŒì¼ì˜ ê²½ë¡œ.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ '{pdf_file_path}' íŒŒì¼ íŒŒì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    try:\n",
    "        # parsing instruction ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # LlamaParse ì„¤ì •\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            parsing_mode=\"Unstructured\",\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 1. LlamaParseë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "        # 'documents' ê°ì²´ëŠ” ì´ í•¨ìˆ˜ ì™¸ë¶€ì—ì„œ ë¯¸ë¦¬ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        parsed_docs = documents.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 2. LangChain í˜•ì‹ì˜ ë„íë¨¼íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 3. ì €ì¥í•  Markdown íŒŒì¼ì˜ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (í™•ì¥ì ë³€ê²½)\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 4. ëª¨ë“  í˜ì´ì§€ì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "        #    í˜ì´ì§€ ì‚¬ì´ëŠ” ë‘ ì¤„ë¡œ ë„ì–´ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 5. ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ .md íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "\n",
    "# --- í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ ---\n",
    "# ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— 'documents' íŒŒì„œ ê°ì²´ë¥¼ ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# file_to_parse = \"data/ë””ì§€í„¸ì •ë¶€í˜ì‹ ì¶”ì§„ê³„íš.pdf\"\n",
    "file_to_parse = \"./data/í´ë¼ìš°ë“œë„¤ì´í‹°ë¸Œ1-2.pdf\"\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bf825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hTuzgesB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
