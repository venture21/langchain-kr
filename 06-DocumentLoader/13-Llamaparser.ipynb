{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8382978f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LlamaParser\n",
    " \n",
    "LlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다. 주요 특징은 다음과 같습니다:\n",
    "\n",
    "- PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원\n",
    "- 자연어 지시를 통한 맞춤형 출력 형식 제공\n",
    "- 복잡한 표와 이미지 추출 기능\n",
    "- JSON 모드 지원\n",
    "- 외국어 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ec026",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca7f57",
   "metadata": {},
   "source": [
    "LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "사용자는 무료로 한달에 10,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n",
    "\n",
    "- 링크: https://cloud.llamaindex.ai\n",
    "\n",
    "**API 키 설정**\n",
    "- API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de92eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850910e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# jupyter 환경에서 asyncio를 사용할 수 있도록 설정\n",
    "# 이는 Jupyter Notebook에서 비동기 작업을 지원하기 위해 필요합니다.\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3b85",
   "metadata": {},
   "source": [
    "기본 파서 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a94cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0c29b0be-a687-42f1-b7bf-2805f04a458c\n",
      "."
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 파서 설정\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,  # worker 수 (기본값: 4)\n",
    "    verbose=True,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParse로 파싱하고자하는 파일 목록을 input_files에 지정합니다.\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4aabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이지 수 확인\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a08fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='128451be-2864-49f0-a173-4a28fc5ac9bd', embedding=None, metadata={'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-08-21', 'last_modified_date': '2025-08-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='# 인공지능 산업의 최신 동향\\n\\n# 2023년 12월호\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d4e1b",
   "metadata": {},
   "source": [
    "LlamaIndex -> LangChain Document 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10be578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db68c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "6  Z. Shen et al.\n",
      "\n",
      "Fig. 2: The relationship between the three types of layout data structures. Coordinate supports three kinds of variation; TextBlock consists of the coordinate information and extra features like block text, types, and reading orders; a Layout object is a list of all possible layout elements, including other Layout objects. They all support the same set of transformation and operation APIs for maximum flexibility.\n",
      "\n",
      "Shown in Table 1, LayoutParser currently hosts 9 pre-trained models trained on 5 different datasets. Description of the training dataset is provided alongside with the trained models such that users can quickly identify the most suitable models for their tasks. Additionally, when such a model is not readily available, LayoutParser also supports training customized layout models and community sharing of the models (detailed in Section 3.5).\n",
      "\n",
      "# 3.2  Layout Data Structures\n",
      "\n",
      "A critical feature of LayoutParser is the implementation of a series of data structures and operations that can be used to efficiently process and manipulate the layout elements. In document image analysis pipelines, various post-processing on the layout analysis model outputs is usually required to obtain the final outputs. Traditionally, this requires exporting DL model outputs and then loading the results into other pipelines. All model outputs from LayoutParser will be stored in carefully engineered data types optimized for further processing, which makes it possible to build an end-to-end document digitization pipeline within LayoutParser. There are three key components in the data structure, namely the Coordinate system, the TextBlock, and the Layout. They provide different levels of abstraction for the layout data, and a set of APIs are supported for transformations or operations on these classes.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ec141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data\\\\2103.15348v2.pdf',\n",
       " 'file_name': '2103.15348v2.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 4686220,\n",
       " 'creation_date': '2025-08-22',\n",
       " 'last_modified_date': '2025-08-22'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 출력\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845a3bc",
   "metadata": {},
   "source": [
    "## MultiModal Model 로 파싱\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n",
    "\n",
    "- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
    "\n",
    "- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
    "\n",
    "- `result_type`: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
    "\n",
    "- `language`: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n",
    "\n",
    "- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
    "\n",
    "- `page_separator`: 페이지 구분자를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI = False\n",
    "if GEMINI:\n",
    "    multimodal_model_name = \"gemini-2.5-pro\"\n",
    "    multimodal_api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "else:\n",
    "    multimodal_model_name = \"openai-gpt4o\"\n",
    "    multimodal_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "    # LlamaParse 설정\n",
    "\n",
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=multimodal_model_name,\n",
    "    vendor_multimodal_api_key=multimodal_api_key,\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c986f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b50de87a-8447-4ad7-bb79-3bd4e513838f\n"
     ]
    }
   ],
   "source": [
    "# parsing 된 결과\n",
    "# file_path = \"data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55bb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb571cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파일 저장 완료: data/2103.15348v2.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "# os.path.splitext()를 사용하여 경로와 확장자를 분리하고, 새로운 확장자를 붙입니다.\n",
    "# file_root는 'data/2103.15348v2'가 됩니다.\n",
    "file_root, _ = os.path.splitext(file_path)\n",
    "output_file_path = file_root + \".md\"\n",
    "\n",
    "# 1. 모든 페이지의 page_content를 리스트로 추출합니다.\n",
    "#    각 페이지 사이를 두 줄 띄어쓰기(\\n\\n)로 구분하여 가독성을 높입니다.\n",
    "full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 2. 추출한 전체 텍스트를 파일에 저장합니다.\n",
    "#    'w' 모드는 파일을 쓰기 모드로 열며, encoding='utf-8'은 한글 깨짐을 방지합니다.\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"✅ 파일 저장 완료: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efd3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 정책/정책\n",
      "\n",
      "# 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표\n",
      "\n",
      "**KEY Contents**\n",
      "\n",
      "- 미국 바이든 대통령이 '안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령'에 서명하고 광범위한 행정 조치를 명시\n",
      "- 행정명령은 AI의 안전과 보안 기준 마련, 개인정보보호, 소행성화와 시민권 향상, 소비자 보호, 노동자 지원, 습식내 경쟁 촉진, 스크재협력을 골자로 함\n",
      "\n",
      "## 바이든 대통령, AI 행정명령 통해 안전하고 신뢰할 수 있는 AI 개발과 활용 추진\n",
      "\n",
      "- 미국 바이든 대통령이 2023년 10월 30일 연방정부 차원에서 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표\n",
      "- 행정명령은 AI의 안전과 보안 기준 마련, 개인정보보호, 소행성화와 시민권 향상, 소비자 보호, 노동자 지원, 습식내 경쟁 촉진, 스크재협력에 관한 내용을 포함\n",
      "- (AI 안전과 보안 기준) 강화된 AI 시스템을 개발하는 기업에게 안전 테스트 결과와 시스템에 관한 주요 정보를 미국 정부와 공유할 것을 요구하고, AI 시스템의 안전성과 신뢰성 확인을 위한 표준 및 AI 생성 콘텐츠 표시를 위한 표준과 모바일 AI 활용을 추진\n",
      "- 10<sup>26</sup> 플롭스(FLOPS, Floating Point Operation Per Second)를 초과하는 컴퓨터 성능 또는 상용화적 서열 데이터를 주로 사용하는 10<sup>3</sup>플롭스를 초과하는 컴퓨터 성능을 사용하는 모델 스탠딩 데이터센터에서 1,000기가 이상의 네트워크로 연결되며 AI 훈련에서 이로한 최대 10<sup>20</sup> 플롭스를 처리할 수 있는 컴퓨터 용량을 갖춘 클러스터가 정보공유 요구대상\n",
      "- (행동성과 시민권 향상) 법률, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타 문제를 방지하는 조치를 확대\n",
      "- 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한 지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\n",
      "- (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교 내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과 모범사례를 마련\n",
      "- (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)을 통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자의 기술과 인프라를 지원\n",
      "  - 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\n",
      "  - 비자 기준을 디지털 적합성에 간소화로 AI 관련 주요 분야의 전문 자격을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원\n",
      "\n",
      "출처: The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (E.O. 14110), 2023.10.30.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc038703",
   "metadata": {},
   "source": [
    "아래와 같이 사용자 정의 인스트럭션을 지정하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing instruction 을 지정합니다.\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse 설정\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing 된 결과\n",
    "parsed_docs = parser.load_data(file_path=file_path)\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 형식으로 추출된 테이블 확인\n",
    "print(docs[-2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec963cd",
   "metadata": {},
   "source": [
    "### LLAMA_PARSER를 함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c33002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 './data/클라우드네이티브1-2.pdf' 파일 파싱을 시작합니다...\n",
      "Started parsing the file under job_id 555fa74a-64fb-45be-b0d6-052addd2f4c3\n",
      "✅ 파일 저장 완료: ./data/클라우드네이티브1-2.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\")\n",
    "\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): 처리할 PDF 파일의 경로.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "\n",
    "    try:\n",
    "        # parsing instruction 을 지정합니다.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # LlamaParse 설정\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            parsing_mode=\"Unstructured\",\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 1. LlamaParse를 사용하여 PDF 파일을 로드합니다.\n",
    "        # 'documents' 객체는 이 함수 외부에서 미리 정의되어 있어야 합니다.\n",
    "        parsed_docs = documents.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 2. LangChain 형식의 도큐먼트로 변환합니다.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 3. 저장할 Markdown 파일의 경로를 생성합니다. (확장자 변경)\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 4. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.\n",
    "        #    페이지 사이는 두 줄로 띄어 가독성을 높입니다.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 5. 추출된 전체 텍스트를 .md 파일로 저장합니다.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 함수 사용 예시 ---\n",
    "# 이 코드를 실행하기 전에 'documents' 파서 객체를 초기화해야 합니다.\n",
    "# file_to_parse = \"data/디지털정부혁신추진계획.pdf\"\n",
    "file_to_parse = \"./data/클라우드네이티브1-2.pdf\"\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bf825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hTuzgesB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
