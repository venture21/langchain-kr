{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9781df",
   "metadata": {},
   "source": [
    "# TokenTextSplitter\n",
    "\n",
    "ì–¸ì–´ ëª¨ë¸ì—ëŠ” í† í° ì œí•œì´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í† í° ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "`TokenTextSplitter` ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í° ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì²­í¬ë¥¼ ìƒì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299ad02",
   "metadata": {},
   "source": [
    "## tiktoken\n",
    "\n",
    "`tiktoken` ì€ OpenAIì—ì„œ ë§Œë“  ë¹ ë¥¸ `BPE Tokenizer` ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365c78f",
   "metadata": {},
   "source": [
    "- `./data/appendix-keywords.txt` íŒŒì¼ì„ ì—´ì–´ ë‚´ìš©ì„ ì½ì–´ë“¤ì…ë‹ˆë‹¤.\n",
    "- ì½ì–´ë“¤ì¸ ë‚´ìš©ì„ `file` ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8919094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16d938",
   "metadata": {},
   "source": [
    "íŒŒì¼ë¡œë¶€í„° ì½ì€ íŒŒì¼ì˜ ì¼ë¶€ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bfdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
      "\n",
      "Embedding\n",
      "\n",
      "ì •ì˜: ì„ë² ë”©ì€ ë‹¨ì–´ë‚˜ ë¬¸ì¥ ê°™ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì°¨ì›ì˜ ì—°ì†ì ì¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì»´í“¨í„°ê°€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: \"ì‚¬ê³¼\"ë¼ëŠ” ë‹¨ì–´ë¥¼ [0.65, -0.23, 0.17]ê³¼ ê°™ì€ ë²¡í„°ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ë²¡í„°í™”, ë”¥ëŸ¬ë‹\n",
      "\n",
      "Token\n",
      "\n",
      "ì •ì˜: í† í°ì€ í…ìŠ¤íŠ¸ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì–´, ë¬¸ì¥, ë˜ëŠ” êµ¬ì ˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: ë¬¸ì¥ \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤\"ë¥¼ \"ë‚˜ëŠ”\", \"í•™êµì—\", \"ê°„ë‹¤\"ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: í† í°í™”, ìì—°ì–´\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68155bf",
   "metadata": {},
   "source": [
    "`CharacterTextSplitter`ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `from_tiktoken_encoder` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ Tiktoken ì¸ì½”ë” ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe585376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    # ì²­í¬ í¬ê¸°ë¥¼ 400ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    # 300ì¸ ê²½ìš° ì•„ë˜ì™€ ê°™ì€ ë©”ì„¸ì§€ê°€ ëœ¬ë‹¤.\n",
    "    # Created a chunk of size 358, which is longer than the specified 300\n",
    "    chunk_size=400,\n",
    "    # ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¶€ë¶„ì´ ì—†ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "# file í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "texts = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8815d8e",
   "metadata": {},
   "source": [
    "ë¶„í• ëœ ì²­í¬ì˜ ê°œìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d531f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2103054d",
   "metadata": {},
   "source": [
    "texts ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4edccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
      "\n",
      "Embedding\n"
     ]
    }
   ],
   "source": [
    "# texts ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34aaa8b",
   "metadata": {},
   "source": [
    "**ì°¸ê³ **\n",
    "\n",
    "- `CharacterTextSplitter.from_tiktoken_encoder`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, í…ìŠ¤íŠ¸ëŠ” `CharacterTextSplitter`ì— ì˜í•´ì„œë§Œ ë¶„í• ë˜ê³  `tiktoken` í† í¬ë‚˜ì´ì €ëŠ” ë¶„í• ëœ í…ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. (ì´ëŠ” ë¶„í• ëœ í…ìŠ¤íŠ¸ê°€ `tiktoken` í† í¬ë‚˜ì´ì €ë¡œ ì¸¡ì •í•œ ì²­í¬ í¬ê¸°ë³´ë‹¤ í´ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.)\n",
    "\n",
    "- `RecursiveCharacterTextSplitter.from_tiktoken_encoder`ë¥¼ ì‚¬ìš©í•˜ë©´ ë¶„í• ëœ í…ìŠ¤íŠ¸ê°€ ì–¸ì–´ ëª¨ë¸ì—ì„œ í—ˆìš©í•˜ëŠ” í† í°ì˜ ì²­í¬ í¬ê¸°ë³´ë‹¤ í¬ì§€ ì•Šë„ë¡ í•  ìˆ˜ ìˆìœ¼ë©°, ê° ë¶„í• ì€ í¬ê¸°ê°€ ë” í° ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ë¶„í• ë©ë‹ˆë‹¤. ë˜í•œ tiktoken ë¶„í• ê¸°ë¥¼ ì§ì ‘ ë¡œë“œí•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ê° ë¶„í• ì´ ì²­í¬ í¬ê¸°ë³´ë‹¤ ì‘ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce2732",
   "metadata": {},
   "source": [
    "## TokenTextSplitter\n",
    "\n",
    "- `TokenTextSplitter` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3ab133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "ì—°ï¿½\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=300,  # ì²­í¬ í¬ê¸°ë¥¼ 10ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    chunk_overlap=0,  # ì²­í¬ ê°„ ì¤‘ë³µì„ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# state_of_the_union í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "texts = text_splitter.split_text(file)\n",
    "print(texts[0])  # ë¶„í• ëœ í…ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ì²­í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b017ab",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "\n",
    "spaCyëŠ” Pythonê³¼ Cython í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì‘ì„±ëœ ê³ ê¸‰ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "NLTKì˜ ë˜ ë‹¤ë¥¸ ëŒ€ì•ˆì€ spaCy tokenizerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "1. í…ìŠ¤íŠ¸ê°€ ë¶„í• ë˜ëŠ” ë°©ì‹: **spaCy tokenizer**ì— ì˜í•´ ë¶„í• ë©ë‹ˆë‹¤.\n",
    "\n",
    "2. chunk sizeê°€ ì¸¡ì •ë˜ëŠ” ë°©ë²•: **ë¬¸ì ìˆ˜**ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613e215",
   "metadata": {},
   "source": [
    "spaCy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” pip ëª…ë ¹ì–´ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33f71a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7bb1e",
   "metadata": {},
   "source": [
    "`en_core_web_sm` ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd2d49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654384df",
   "metadata": {},
   "source": [
    "- `appendix-keywords.txt` íŒŒì¼ì„ ì—´ì–´ ë‚´ìš©ì„ ì½ì–´ë“¤ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04bd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4faf39",
   "metadata": {},
   "source": [
    "ì¼ë¶€ ë‚´ìš©ì„ ì¶œë ¥í•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e53e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜ë¦¬, ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° ë§ˆì´ë‹\n",
      "\n",
      "Embedding\n",
      "\n",
      "ì •ì˜: ì„ë² ë”©ì€ ë‹¨ì–´ë‚˜ ë¬¸ì¥ ê°™ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì €ì°¨ì›ì˜ ì—°ì†ì ì¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì»´í“¨í„°ê°€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
      "ì˜ˆì‹œ: \"ì‚¬ê³¼\"ë¼ëŠ” ë‹¨ì–´ë¥¼ [0.65, -0.23, 0.17]ê³¼ ê°™ì€ ë²¡í„°ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
      "ì—°ê´€í‚¤ì›Œë“œ: ìì—°ì–´ ì²˜\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20652a",
   "metadata": {},
   "source": [
    "- `SpacyTextSplitter` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9c4e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\park0\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\park0\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\park0\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\park0\\AppData\\Local\\Temp\\ipykernel_20828\\3988215695.py\", line 8, in <module>\n",
      "    text_splitter = SpacyTextSplitter(\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\langchain_text_splitters\\spacy.py\", line 28, in __init__\n",
      "    self._tokenizer = _make_spacy_pipeline_for_splitting(\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\langchain_text_splitters\\spacy.py\", line 47, in _make_spacy_pipeline_for_splitting\n",
      "    import spacy\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\park0\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-hTuzgesB-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from langchain_text_splitters import SpacyTextSplitter\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# SpacyTextSplitterë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "text_splitter = SpacyTextSplitter(\n",
    "    chunk_size=200,  # ì²­í¬ í¬ê¸°ë¥¼ 200ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    chunk_overlap=50,  # ì²­í¬ ê°„ ì¤‘ë³µì„ 50ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dfbcd",
   "metadata": {},
   "source": [
    "- `text_splitter` ê°ì²´ì˜ `split_text` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `file` í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f1e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "ì •ì˜: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì€ ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ë„˜ì–´ì„œ ê·¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ê´€ë ¨ëœ\n",
      "\n",
      "ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "ì˜ˆì‹œ: ì‚¬ìš©ìê°€ \"íƒœì–‘ê³„ í–‰ì„±\"ì´ë¼ê³  ê²€ìƒ‰í•˜ë©´, \"ëª©ì„±\", \"í™”ì„±\" ë“±ê³¼ ê°™ì´ ê´€ë ¨ëœ í–‰ì„±ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# text_splitterë¥¼ ì‚¬ìš©í•˜ì—¬ file í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "texts = text_splitter.split_text(file)\n",
    "print(texts[0])  # ë¶„í• ëœ í…ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585c693",
   "metadata": {},
   "source": [
    "## SentenceTransformers\n",
    "\n",
    "`SentenceTransformersTokenTextSplitter`ëŠ” `sentence-transformer` ëª¨ë¸ì— íŠ¹í™”ëœ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ ë™ì‘ì€ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” sentence transformer ëª¨ë¸ì˜ í† í° ìœˆë„ìš°ì— ë§ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876a3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 2.xì™€ í˜¸í™˜ë˜ëŠ” sentence-transformers ìµœì‹  ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤\n",
    "!pip install \"sentence-transformers>=3.0.0\"itter í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° ë°©ë²•ë“¤\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"ğŸ”§ SentenceTransformersTokenTextSplitter ë¬¸ì œ í•´ê²° ì‹œë„ ì¤‘...\")\n",
    "\n",
    "# ë°©ë²• 1: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ NumPy í˜¸í™˜ì„± ë¬¸ì œ ìš°íšŒ\n",
    "import os\n",
    "os.environ['SCIPY_DISABLE_UFUNC_VALIDATION'] = '1'\n",
    "\n",
    "# ë°©ë²• 2: í˜¸í™˜ë˜ëŠ” ë²„ì „ì˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "try:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    print(\"ğŸ“¦ í˜¸í™˜ ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€ ë²„ì „ ì„¤ì¹˜ ì¤‘...\")\n",
    "    \n",
    "    # NumPyì™€ SciPyë¥¼ í˜¸í™˜ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜\n",
    "    packages_to_install = [\n",
    "        \"numpy==1.24.3\",\n",
    "        \"scipy==1.10.1\", \n",
    "        \"sentence-transformers==2.2.2\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages_to_install:\n",
    "        print(f\"  ì„¤ì¹˜ ì¤‘: {package}\")\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", package],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            print(f\"  âš ï¸ {package} ì„¤ì¹˜ ì‹¤íŒ¨, ê³„ì† ì§„í–‰...\")\n",
    "    \n",
    "    print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ë°©ë²• 3: ì»¤ë„ ì¬ì‹œì‘ ì—†ì´ ëª¨ë“ˆ ë‹¤ì‹œ ë¡œë“œ\n",
    "try:\n",
    "    import importlib\n",
    "    import sys\n",
    "    \n",
    "    # ì´ë¯¸ ë¡œë“œëœ ëª¨ë“ˆë“¤ ì œê±°\n",
    "    modules_to_reload = [\n",
    "        'sentence_transformers', 'scipy', 'numpy',\n",
    "        'langchain_text_splitters'\n",
    "    ]\n",
    "    \n",
    "    for module in modules_to_reload:\n",
    "        if module in sys.modules:\n",
    "            del sys.modules[module]\n",
    "    \n",
    "    print(\"ğŸ”„ ëª¨ë“ˆ ì¬ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ëª¨ë“ˆ ì¬ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ í•´ê²° ë°©ë²• ìš”ì•½:\")\n",
    "print(\"1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ SciPy ê²€ì¦ ë¹„í™œì„±í™”\")\n",
    "print(\"2. í˜¸í™˜ ë²„ì „ íŒ¨í‚¤ì§€ ì„¤ì¹˜\")\n",
    "print(\"3. ëª¨ë“ˆ ì¬ë¡œë“œ\")\n",
    "print(\"\\në‹¤ìŒ ì…€ì—ì„œ SentenceTransformersTokenTextSplitterë¥¼ ì‹œë„í•©ë‹ˆë‹¤...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c098ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c366ccff646339e4e0019b23affab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c366ccff646339e4e0019b23affab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837c13df7a044343b459ea5cadae1de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c366ccff646339e4e0019b23affab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837c13df7a044343b459ea5cadae1de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e09edac2a940248e2e810d5df6486e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c366ccff646339e4e0019b23affab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837c13df7a044343b459ea5cadae1de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e09edac2a940248e2e810d5df6486e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ce2de2c8e4427cac46d023fb995a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559e344e0754579a92d3e1215fc9694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef07255dbf4f3a9a18f2bffe75bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e74e2319414a42b2d19a4da83457dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77afe7997a54705aef0982d73a75589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cb0c1f034245bddf9c155c6513f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d509f5a3d37e4162944b37925fea9447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c366ccff646339e4e0019b23affab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837c13df7a044343b459ea5cadae1de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e09edac2a940248e2e810d5df6486e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ce2de2c8e4427cac46d023fb995a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37d961659d848dbb261a2b2d5f5fd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "# ë¬¸ì¥ ë¶„í• ê¸°ë¥¼ ìƒì„±í•˜ê³  ì²­í¬ ê°„ ì¤‘ë³µì„ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "splitter = SentenceTransformersTokenTextSplitter(chunk_size=200, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54516251",
   "metadata": {},
   "source": [
    "ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ SentenceTransformersTokenTextSplitter ê³ ê¸‰ ë¬¸ì œ í•´ê²°\n",
    "# ì»¤ë„ ì¬ì‹œì‘ ì—†ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "print(\"ğŸ”§ ê³ ê¸‰ ë¬¸ì œ í•´ê²° ë°©ë²• ì‹œë„ ì¤‘...\")\n",
    "\n",
    "# ë°©ë²• 1: Python ê²½ë¡œì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ëª¨ë“ˆ ì™„ì „ ì œê±°\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "def clean_modules():\n",
    "    \"\"\"ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ëª¨ë“ˆë“¤ì„ ì™„ì „íˆ ì œê±°\"\"\"\n",
    "    modules_to_clean = [\n",
    "        'sentence_transformers', 'transformers', 'torch', \n",
    "        'numpy', 'scipy', 'sklearn', 'langchain_text_splitters'\n",
    "    ]\n",
    "    \n",
    "    for module_name in modules_to_clean:\n",
    "        # ëª¨ë“  í•˜ìœ„ ëª¨ë“ˆë„ í¬í•¨í•˜ì—¬ ì œê±°\n",
    "        modules_to_remove = [name for name in sys.modules.keys() \n",
    "                           if name.startswith(module_name)]\n",
    "        \n",
    "        for module in modules_to_remove:\n",
    "            if module in sys.modules:\n",
    "                del sys.modules[module]\n",
    "    \n",
    "    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰\n",
    "    gc.collect()\n",
    "    print(\"âœ… ëª¨ë“ˆ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# ë°©ë²• 2: í™˜ê²½ ë³€ìˆ˜ë¡œ NumPy ë™ì‘ ì œì–´\n",
    "import os\n",
    "os.environ.update({\n",
    "    'SCIPY_DISABLE_UFUNC_VALIDATION': '1',\n",
    "    'NUMPY_DISABLE_UFUNC_VALIDATION': '1',\n",
    "    'TRANSFORMERS_OFFLINE': '0',\n",
    "    'TOKENIZERS_PARALLELISM': 'false'\n",
    "})\n",
    "\n",
    "print(\"ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# ë°©ë²• 3: ëª¨ë“ˆ ì¬import ì „ì— ì •ë¦¬\n",
    "try:\n",
    "    clean_modules()\n",
    "    \n",
    "    # NumPyì™€ SciPyë¥¼ ë¨¼ì € importí•˜ì—¬ ì´ˆê¸°í™”\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    print(f\"NumPy ë²„ì „: {np.__version__}\")\n",
    "    print(f\"SciPy ë²„ì „: {scipy.__version__}\")\n",
    "    \n",
    "    # ì´ì œ sentence-transformers ì‹œë„\n",
    "    import sentence_transformers\n",
    "    print(f\"sentence-transformers ë²„ì „: {sentence_transformers.__version__}\")\n",
    "    \n",
    "    print(\"âœ… ëª¨ë“  í•µì‹¬ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë“ˆ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"1. ìœ„ì˜ ëª¨ë“  ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆë‹¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "print(\"2. ì—¬ì „íˆ ë¬¸ì œê°€ ìˆë‹¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "print(\"   pip uninstall sentence-transformers -y\")\n",
    "print(\"   pip install sentence-transformers==2.2.2\")\n",
    "print(\"3. ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ê°€ìƒí™˜ê²½ì„ ìƒˆë¡œ ë§Œë“¤ì–´ ì‚¬ìš©í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563a98e",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ `file` ë³€ìˆ˜ì— ë‹´ê¸´ í…ìŠ¤íŠ¸ì˜ í† í°ì˜ ê°œìˆ˜ë¥¼ ì„¸ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ì‹œì‘ê³¼ ì¢…ë£Œ í† í°ì˜ ê°œìˆ˜ë¥¼ ì œì™¸í•œ í›„ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_start_and_stop_tokens = 2  # ì‹œì‘ê³¼ ì¢…ë£Œ í† í°ì˜ ê°œìˆ˜ë¥¼ 2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "# í…ìŠ¤íŠ¸ì˜ í† í° ê°œìˆ˜ì—ì„œ ì‹œì‘ê³¼ ì¢…ë£Œ í† í°ì˜ ê°œìˆ˜ë¥¼ ëºë‹ˆë‹¤.\n",
    "text_token_count = splitter.count_tokens(text=file) - count_start_and_stop_tokens\n",
    "print(text_token_count)  # ê³„ì‚°ëœ í…ìŠ¤íŠ¸ í† í° ê°œìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0691dd26",
   "metadata": {},
   "source": [
    "`splitter.split_text()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `text_to_split` ë³€ìˆ˜ì— ì €ì¥ëœ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬(chunk) ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = splitter.split_text(text=file)  # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5f73e",
   "metadata": {},
   "source": [
    "ì²« ë²ˆì§¸ ì²­í¬ë¥¼ ì¶œë ¥í•˜ì—¬ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6548ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0ë²ˆì§¸ ì²­í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(text_chunks[1])  # ë¶„í• ëœ í…ìŠ¤íŠ¸ ì²­í¬ ì¤‘ ë‘ ë²ˆì§¸ ì²­í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97dd30",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "Natural Language Toolkit (NLTK)ì€ Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì‘ì„±ëœ ì˜ì–´ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë¡œê·¸ë¨ ëª¨ìŒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨ìˆœíˆ \"\\n\\n\"ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ëŒ€ì‹ , NLTK tokenizersë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ëŠ” ë° NLTKë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. í…ìŠ¤íŠ¸ ë¶„í•  ë°©ë²•: NLTK tokenizerì— ì˜í•´ ë¶„í• ë©ë‹ˆë‹¤.\n",
    "2. chunk í¬ê¸° ì¸¡ì • ë°©ë²•: ë¬¸ì ìˆ˜ì— ì˜í•´ ì¸¡ì •ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4ab36",
   "metadata": {},
   "source": [
    "- `nltk` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ëŠ” pip ëª…ë ¹ì–´ì…ë‹ˆë‹¤.\n",
    "- NLTK(Natural Language Toolkit)ëŠ” ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "- í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ì „ì²˜ë¦¬, í† í°í™”, í˜•íƒœì†Œ ë¶„ì„, í’ˆì‚¬ íƒœê¹… ë“± ë‹¤ì–‘í•œ NLP ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e11572",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f61343cb52923",
   "metadata": {},
   "source": [
    "NLTKëŠ” ê¸°ë³¸ ì„¤ì¹˜ ì‹œ ëª¨ë“  ë°ì´í„°ë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ì´ˆê¸° ì„¤ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê³ , ì‚¬ìš©ìê°€ í•„ìš”í•œ ë°ì´í„°ë§Œ ì„ íƒì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. \n",
    "NLTKì—ì„œ ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œëŠ” \"~/nltk_data\"ì— ì„¤ì¹˜ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ad71020b825e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccf971",
   "metadata": {},
   "source": [
    "ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45668c01",
   "metadata": {},
   "source": [
    "`NLTKTextSplitter` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(\n",
    "    chunk_size=200,  # ì²­í¬ í¬ê¸°ë¥¼ 200ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    chunk_overlap=0,  # ì²­í¬ ê°„ ì¤‘ë³µì„ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb83e21",
   "metadata": {},
   "source": [
    "`text_splitter` ê°ì²´ì˜ `split_text` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `file` í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86af73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitterë¥¼ ì‚¬ìš©í•˜ì—¬ file í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "texts = text_splitter.split_text(file)\n",
    "print(texts[0])  # ë¶„í• ëœ í…ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6be336",
   "metadata": {},
   "source": [
    "## KoNLPy\n",
    "\n",
    "KoNLPy(Korean NLP in Python)ëŠ” í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬(NLP)ë¥¼ ìœ„í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n",
    "\n",
    "í† í° ë¶„í• ì€ í…ìŠ¤íŠ¸ë¥¼ í† í°ì´ë¼ê³  í•˜ëŠ” ë” ì‘ê³  ê´€ë¦¬í•˜ê¸° ì‰¬ìš´ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ í† í°ì€ ì¢…ì¢… ë‹¨ì–´, êµ¬, ê¸°í˜¸ ë˜ëŠ” ì¶”ê°€ ì²˜ë¦¬ ë° ë¶„ì„ì— ì¤‘ìš”í•œ ë‹¤ë¥¸ ì˜ë¯¸ ìˆëŠ” ìš”ì†Œì…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ì–´ì™€ ê°™ì€ ì–¸ì–´ì—ì„œ í† í° ë¶„í• ì€ ì¼ë°˜ì ìœ¼ë¡œ ê³µë°±ê³¼ êµ¬ë‘ì ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "í† í° ë¶„í• ì˜ íš¨ê³¼ëŠ” ì–¸ì–´ êµ¬ì¡°ì— ëŒ€í•œ í† í¬ë‚˜ì´ì €ì˜ ì´í•´ì— í¬ê²Œ ì˜ì¡´í•˜ë©°, ì´ëŠ” ì˜ë¯¸ ìˆëŠ” í† í° ìƒì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ì–´ë¥¼ ìœ„í•´ ì„¤ê³„ëœ í† í¬ë‚˜ì´ì €ëŠ” í•œêµ­ì–´ì™€ ê°™ì€ ë‹¤ë¥¸ ì–¸ì–´ì˜ ê³ ìœ í•œ ì˜ë¯¸ êµ¬ì¡°ë¥¼ ì´í•´í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ì—†ê¸° ë•Œë¬¸ì— í•œêµ­ì–´ ì²˜ë¦¬ì— íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### KoNLPyì˜ Kkma ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ í† í° ë¶„í• \n",
    "\n",
    "í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° KoNLPYì—ëŠ” `Kkma`(Korean Knowledge Morpheme Analyzer)ë¼ëŠ” í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "`Kkma`ëŠ” í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ìƒì„¸í•œ í˜•íƒœì†Œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ, ë‹¨ì–´ë¥¼ ê°ê°ì˜ í˜•íƒœì†Œë¡œ ë¶„í•´í•˜ê³  ê° í† í°ì— ëŒ€í•œ í’ˆì‚¬ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.\n",
    "\n",
    "í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ê°œë³„ ë¬¸ì¥ìœ¼ë¡œ ë¶„í• í•  ìˆ˜ ìˆì–´ ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‚¬ìš©ì‹œ ê³ ë ¤ì‚¬í•­\n",
    "\n",
    "`Kkma`ëŠ” ìƒì„¸í•œ ë¶„ì„ìœ¼ë¡œ ìœ ëª…í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ì •ë°€ì„±ì´ ì²˜ë¦¬ ì†ë„ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤ëŠ” ì ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ `Kkma`ëŠ” ì‹ ì†í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ë³´ë‹¤ ë¶„ì„ì  ê¹Šì´ê°€ ìš°ì„ ì‹œë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d535db",
   "metadata": {},
   "source": [
    "- KoNLPy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ëŠ” pip ëª…ë ¹ì–´ì…ë‹ˆë‹¤.\n",
    "- KoNLPyëŠ” í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¡œ, í˜•íƒœì†Œ ë¶„ì„, í’ˆì‚¬ íƒœê¹…, êµ¬ë¬¸ ë¶„ì„ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef21f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421b1fc",
   "metadata": {},
   "source": [
    "ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854203b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c3713",
   "metadata": {},
   "source": [
    "KonlpyTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chunk\n",
    "from langchain_text_splitters import KonlpyTextSplitter\n",
    "\n",
    "# KonlpyTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "text_splitter = KonlpyTextSplitter(chunk_size=200, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7c0ab",
   "metadata": {},
   "source": [
    "`text_splitter`ë¥¼ ì‚¬ìš©í•˜ì—¬ `file`ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(file)  # í•œêµ­ì–´ ë¬¸ì„œë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "print(texts[0])  # ë¶„í• ëœ ë¬¸ì¥ ì¤‘ ì²« ë²ˆì§¸ ë¬¸ì¥ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f3ae9",
   "metadata": {},
   "source": [
    "## Hugging Face tokenizer\n",
    "\n",
    "Hugging FaceëŠ” ë‹¤ì–‘í•œ í† í¬ë‚˜ì´ì €ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì½”ë“œì—ì„œëŠ” Hugging Faceì˜ í† í¬ë‚˜ì´ì € ì¤‘ í•˜ë‚˜ì¸ GPT2TokenizerFastë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ í† í° ê¸¸ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "í…ìŠ¤íŠ¸ ë¶„í•  ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ì „ë‹¬ëœ ë¬¸ì ë‹¨ìœ„ë¡œ ë¶„í• ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì²­í¬ í¬ê¸° ì¸¡ì • ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- Hugging Face í† í¬ë‚˜ì´ì €ì— ì˜í•´ ê³„ì‚°ëœ í† í° ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1ec50",
   "metadata": {},
   "source": [
    "- `GPT2TokenizerFast` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ `tokenizer` ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- `from_pretrained` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ \"gpt2\" í† í¬ë‚˜ì´ì € ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "# GPT-2 ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "hf_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ee3ed",
   "metadata": {},
   "source": [
    "ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd437637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/appendix-keywords.txt íŒŒì¼ì„ ì—´ì–´ì„œ fë¼ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "with open(\"./data/appendix-keywords.txt\") as f:\n",
    "    file = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# íŒŒì¼ìœ¼ë¡œë¶€í„° ì½ì€ ë‚´ìš©ì„ ì¼ë¶€ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d87e41c",
   "metadata": {},
   "source": [
    "`from_huggingface_tokenizer` ë©”ì„œë“œë¥¼ í†µí•´ í—ˆê¹…í˜ì´ìŠ¤ í† í¬ë‚˜ì´ì €(`tokenizer`)ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    # í—ˆê¹…í˜ì´ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ CharacterTextSplitter ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    hf_tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "# state_of_the_union í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ì—¬ texts ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "texts = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46ef64",
   "metadata": {},
   "source": [
    "1 ë²ˆì§¸ ìš”ì†Œì˜ ë¶„í•  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[1])  # texts ë¦¬ìŠ¤íŠ¸ì˜ 1 ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hTuzgesB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
