{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationKGMemory\n",
    "\n",
    "지식 그래프의 힘을 활용하여 정보를 저장하고 불러옵니다.\n",
    "\n",
    "이를 통해 모델이 서로 다른 개체 간의 관계를 이해하는 데 도움을 주고, 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
    "memory.save_context(\n",
    "    {\"input\": \"이쪽은 Pangyo 에 거주중인 김셜리씨 입니다.\"},\n",
    "    #{\"input\": \"이쪽은 판교에 거주중인 김셜리씨 입니다.\"},\n",
    "    {\"output\": \"김셜리씨는 누구시죠?\"},\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"김셜리씨는 우리 회사의 신입 디자이너입니다.\"},\n",
    "    {\"output\": \"만나서 반갑습니다.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Pangyo: Pangyo has resident 김셜리씨.', additional_kwargs={}, response_metadata={}),\n",
       "  SystemMessage(content='On 김셜리씨: 김셜리씨 is a 신입 디자이너. 김셜리씨 is in 우리 회사.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"김셜리씨는 누구입니까?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 에 메모리 활용하기\n",
    "\n",
    "`ConversationChain` 에 `ConversationKGMemory` 를 메모리로 지정하여 대화를 나눈 후 memory 를 확인해 보도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\park0\\AppData\\Local\\Temp\\ipykernel_5600\\4232739924.py:21: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation_with_kg = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationKGMemory에서 LLM의 역할\n",
    "\n",
    "`ConversationKGMemory(llm=llm)`에서 LLM은 다음과 같은 역할을 수행합니다:\n",
    "\n",
    "1. **개체 추출 (Entity Extraction)**: \n",
    "   - 대화에서 중요한 개체(사람, 장소, 사물 등)를 식별\n",
    "   - 예: \"Teddy\", \"Shirley\", \"company\", \"designer\"\n",
    "\n",
    "2. **관계 추출 (Relationship Extraction)**: \n",
    "   - 개체들 간의 관계를 파악\n",
    "   - 예: \"Shirley is a coworker of Teddy\", \"Shirley is a designer at company\"\n",
    "\n",
    "3. **지식 그래프 구성**: \n",
    "   - 추출된 정보를 구조화된 지식 그래프로 변환\n",
    "   - 트리플 형태로 저장: (주체, 관계, 객체)\n",
    "\n",
    "4. **컨텍스트 기반 정보 검색**: \n",
    "   - 질문이 들어오면 관련 지식을 그래프에서 검색하여 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 지식 그래프에 저장된 정보 ===\n",
      "KG 메모리 키: [('Kim Min Soo', 'Seoul', 'lives in'), ('Kim Min Soo', 'software developer', 'is a'), ('Park Jiyoung', 'UI/UX designer', 'is a'), ('Park Jiyoung', 'our team', 'is in')]\n",
      "\n",
      "=== '김민수는 누구인가?' 질문에 대한 관련 정보 ===\n",
      "{'history': ''}\n"
     ]
    }
   ],
   "source": [
    "# ConversationKGMemory의 동작 방식 확인\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 독립적인 KG Memory 생성\n",
    "kg_memory = ConversationKGMemory(llm=llm)\n",
    "\n",
    "# 대화 저장\n",
    "kg_memory.save_context(\n",
    "    {\"input\": \"안녕하세요! 저는 서울에 사는 김민수입니다. 저는 소프트웨어 개발자로 일하고 있어요.\"},\n",
    "    {\"output\": \"안녕하세요 김민수님! 만나서 반갑습니다.\"}\n",
    ")\n",
    "\n",
    "kg_memory.save_context(\n",
    "    {\"input\": \"제 동료인 박지영씨도 소개해드릴게요. 박지영씨는 우리 팀의 UI/UX 디자이너입니다.\"},\n",
    "    {\"output\": \"박지영님도 만나서 반갑네요!\"}\n",
    ")\n",
    "\n",
    "# 지식 그래프에서 추출된 정보 확인\n",
    "print(\"=== 지식 그래프에 저장된 정보 ===\")\n",
    "print(\"KG 메모리 키:\", list(kg_memory.kg.get_triples()))\n",
    "\n",
    "# 특정 질문에 대한 관련 정보 검색\n",
    "print(\"\\n=== '김민수는 누구인가?' 질문에 대한 관련 정보 ===\")\n",
    "relevant_info = kg_memory.load_memory_variables({\"input\": \"김민수는 누구인가요?\"})\n",
    "print(relevant_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 대화를 시작합니다. 간단한 인물에 대한 정보를 제공해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Teddy! It's nice to meet you. Shirley must be a talented designer if she's new at your company. What kind of projects is she working on?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(\n",
    "    input=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shirley 라는 사람에 대한 질문을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"On Shirley: Shirley is a coworker of Teddy. Shirley is a new designer at Teddy's company.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shirley 에 대한 질문\n",
    "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shirley?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-hTuzgesB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
